# MVDSC: A Multimodal Vulnerability Dataset for Source Code

This repository provides information and access to the MVDSC (Multisource Deep Learner Vulnerability Dataset for Source Code). This dataset is designed for training and evaluating machine learning models for software vulnerability detection.

## About The Project

MVDSC is a comprehensive, multimodal dataset created for the task of static vulnerability detection in source code. The dataset was generated by processing two primary sources: the National Vulnerability Database (NVD) and the Software Assurance Reference Dataset (SARD).

Unlike other datasets derived from the same sources, MVDSC has been carefully cleaned to remove duplicates and mislabeled instances, providing a more reliable basis for model training and evaluation.

The project is associated with the paper:
"Software Vulnerability Detection via Multimodal Deep Learning" by Xin Zhou and Rakesh M. Verma.

## Dataset Description

MVDSC represents source code through four distinct modalities, allowing models to learn from different representations of the code.

### Modalities
The four modalities included for each code sample are:
1.  **Token**: A sequence of lexical tokens extracted from the sliced code based on its Program Dependence Graph (PDG).
2.  **Abstract Syntax Tree Graph (ASTG)**: A graph representation generated from the Abstract Syntax Tree of the source code.
3.  **Tokenized Data Flow Graph (TDFG)**: A graph modality constructed based on data flow dependencies within the tokenized program.
4.  **Heuristic Features (HF)**: A set of 49 features generated from the properties of the AST and tokens, capturing syntactic complexity properties like the number of variable operations and function calls.

### MVDSC-Mixed
The repository also includes MVDSC-Mixed, a version of the dataset that incorporates a small portion of synthetic, adversarial instances to test model robustness.

## Data Preprocessing and Tokenization

To ensure the quality of the dataset and prevent data leakage, a specific preprocessing and tokenization pipeline was used:

* **Masking**: Sensitive information that could trivially give away the label of a sample was masked. This includes any token containing "bad", "good", or "cwe", which were converted to a common string. All comments were removed.
* **String Abstraction**: All strings within single or double quotation marks were converted to an abstract representation that includes the length of the string content.
* **Identifier Tokenization**: The `pycparser` library was used to identify and mask variable and function names. A "Locate ID" method was employed to ensure that variable names are indexed meaningfully and consistently, with sink variables always being indexed before source variables (e.g., strcpy(*ID_0*, *ID_1*)).
* **Number Abstraction**: A function was applied to convert numbers into a format of (*MIN*, difference), where *MIN* is the minimum numerical value across all related data dependents.

## Dataset Statistics

The MVDSC and MVDSC-Mixed datasets are split into training, validation, and testing sets as follows (vulnerable:non-vulnerable):

Dataset        | Train          | Validation   | Test
--------------------------------------------------------------
MVDSC          | 7569 : 22416   | 1914 : 5580  | 1857 : 5637

MVDSC-Mixed    | 11416 : 26569  | 2401 : 6093  | 2325 : 6169

## Download

* **MVDSC**: [Download Link](https://drive.google.com/file/d/13mH5knxm16-yUhcaaWm5aTOFXJWhWH9T/view?usp=drive_link)
* **MVDSC-MIXED**: [Download Link](https://drive.google.com/file/d/1igyLnKaVxKOwEb7y5a6O3TkggCLnXzH7/view?usp=drive_link)


## Citation

If you use the MVDSC dataset in your research, please cite our paper:

  - @inproceedings{zhou2022software,
    title={Software Vulnerability Detection via Multimodal Deep Learning},
    author={Zhou, Xin and Verma, Rakesh M.},
    booktitle={Computer Security--ESORICS 2022: 27th European Symposium on Research in Computer Security, Copenhagen, Denmark, September 26--30, 2022, Proceedings, Part I},
    pages={1--20},
    year={2022},
    organization={Springer}
  }

  - @inproceedings{zhou2022vulnerability,
    title={Vulnerability detection via multimodal learning: Datasets and analysis},
    author={Zhou, Xin and Verma, Rakesh M},
    booktitle={Proceedings of the 2022 ACM Asia Conference on Computer and Communications Security},
    pages={1037--1039},
    year={2022}
  }


## Acknowledgments
Research was partially supported by NSF grants 1433817 and 2210198, ARO grant W911NF-20-1-0254, and ONR award N00014-19-S-F009.
